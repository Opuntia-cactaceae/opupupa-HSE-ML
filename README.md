# **Что было сделано**
`Подробное описание шагов с выводами для каждого в более неформальном виде представлено в ноутбуке, для отчета информация сокращена и формализована + добавлена небольшая гпт агрегация в пункты (все проверено и отредактировано)`

## 1. Базовый EDA, пропуски и дубликаты

### 1.1. Пропуски и дубликаты

- Определены колонки с пропусками в трейне и тесте методом `isna().sum()`.
- Найдены и выведены явные дубликаты:
  - В трейне проверка на дубли по всем признакам.
  - В отдельности посчитано количество полных дубликатов и дубликатов по признакам без целевой.

### 1.2. Профилирование датасета

- Построен отчёт `ydata_profiling` для трейна:
  - Обнаружены дубликаты.
  - Выявлены проблемы с признаками `mileage`, `engine`, `max_power`, `torque`.
  - Замечен сильный дисбаланс по `seller_type`.
  - Выбросы по числовым признакам выглядят приемлемо.

### 1.3. Первичные выводы

- Распределения в трейне и тесте в целом сопоставимы, существенных сдвигов нет.
- Большое стандартное отклонение у `selling_price` ожидаемо для цен на автомобили.
- Потенциальные скрытые дубликаты:
  - Разные единицы измерения (например, `kmpl` и `kmkg`).
  - Текстовые признаки с разным порядком слов и опечатками.
  - Разные форматы записи `torque`.  

## 2. Преобразование признаков

### 2.1. Очистка `max_power` (трейн)

- Из строкового значения извлечена числовая часть и преобразована во `float`.

### 2.2. Преобразование `mileage`, `engine`, `max_power` (трейн и тест)

- Для `mileage`:
  - Извлечена числовая часть.
  - `kmkg` приведены к условному эквиваленту `kmpl` (по гпт формуле).
- Для `engine` и `max_power`:
  - Удалены единицы измерения.
  - Преобразование к `float`.

### 2.3. Разбиение `torque`

- Выполнен разбор строк `torque` с помощью регулярных выражений.
- Учтены разные форматы и единицы (`Nm`, `kgm`):
  - Значения в `kgm` переведены в `Nm`.
- Созданы два числовых признака:
  - `torque` — крутящий момент в `Nm`.
  - `max_torque_rpm` — обороты, при которых достигается максимальный момент.

## 3. Обработка пропусков и приведение типов

### 3.1. Заполнение пропусков

- Определён список колонок с пропусками в трейне.
- Для этих колонок вычислены медианы по трейну.
- Заполнение:
  - В трейне и тесте пропуски заполнены медианами, рассчитанными по трейну.

### 3.2. Приведение типов

- Признаки `engine` и `seats` приведены к типу `int`.

### 3.3. Проверка влияния заполнения пропусков

- Повторно выполнен `describe()` для числовых признаков трейна и теста.
- Пропусков не осталось.
- Количество пропусков было невелико (порядка ~200 в трейн и ~20 в тест), поэтому значимого смещения распределений не ожидается.

## 4. Визуализации распределений (pairplot)

- Построены `pairplot` для числовых признаков в трейне и тесте.
- Наблюдаемые связи с целевой `selling_price`:
  - Прямая связь: `max_power`, `engine`, `year`.
  - Обратная связь: `km_driven`.
- Дополнительные особенности:
  - Необычное распределение `seats`, что логично описывается типами авто (меньше мест — спорткары, больше — минивэны).
  - В тесте видны аналогичные тренды, меньшая плотность точек из-за меньшего объёма данных.


## 5. Корреляционный анализ

### 5.1. Линейная корреляция (Пирсон)

- Вычислена корреляционная матрица (трейн) с помощью `pd.corr()` (по умолчанию — Пирсон).
- Построена тепловая карта (`seaborn.heatmap`).
- Основные наблюдения:
  - Наименьшая корреляция (ближе всего к 0): `engine` и `year`.
  - Сильные положительные связи:
    - `max_power` и целевая: ~0.69.
    - `engine` и `max_power`: ~0.68.
    - `engine` и `seats`: ~0.65.
    - `max_power` и `torque`: ~0.62.
    - `torque` и `engine`: ~0.57.
  - Обратная корреляция `year` и `km_driven`: чем старше автомобиль, тем больше пробег — гипотеза подтверждается.

### 5.2. Спирмен

- Реализована собственная функция для подсчёта корреляции Спирмена, в ней:
  - Производился расчёт рангов.
  - Использовалась классическая формула через суммы квадратов разностей рангов.
- Результат сравним с библиотечной реализацией `pandas`:
  - При корректном учёте повторяющихся значений результаты совпали.

### 5.3. Нелинейная корреляция (phik)

- Построена матрица корреляций `phik`.
- Наблюдения:
  - Появляется множество сильных нелинейных зависимостей, в том числе между целевой и некоторыми признаками.
  - Зависимость с `name` признана нежелательной для продовой модели (это признак которого будет точно не достаточно в проде для предсказания, так мы просто испортим модельку дав ей прямо информацию для прохождения теста).
  - Почти все ключевые числовые признаки существенно связаны с целевой. 

## 6. Дополнительные визуализации (бонус)

- Построен график средней `selling_price` по годам:
  - Зависимость явно **нелинейная**.
  - Видна смена поведения после определённых годов (в поздних годах остаются в основном более дешёвые модели, не уверен каким событием на рынке это объясняется).
- Построена сглаженная зависимость (LOWESS) `selling_price` от `km_driven`:
  - В линейной шкале пробега зависимость плохо читается из-за вытянутого хвоста.
  - После логарифмирования `km_driven` (`km_driven_log`) связь становится более явной:
    - Цена снижается с ростом логарифма пробега.

## 7. Метрики

Для оценки моделей будем использовать `R²` и  `MSE`, также вручную реализована  формула для `R²` и  формула для `adjusted R²`. Эти метрики используются для оценки того, насколько хорошо модель объясняет вариацию целевой переменной:  

- `R²` показывает, насколько модель лучше тривиального предсказания среднего значения;  
- `adjusted R²` корректирует качество с учётом числа признаков, предотвращая ложное улучшение результата при добавлении слабых или нерелевантных факторов.  

Для оценки последующих моделей будут использованы эти же метрики (`R²`, `MSE`).

## 8. Обучение моделей (вещественные признаки)

### 8.1. Линейная регрессия (StandardScaler + LinearRegression)

После масштабирования признаков обучена базовая линейная модель.  
Полученные метрики:

- **Train:** R² ≈ 0.539, MSE ≈ 1.32e11  
- **Test:** R² ≈ 0.569, MSE ≈ 2.48e11  

**Вывод:** модель не переобучена — показатели на трейне и тесте близки.  
Качество ограничено из-за наличия нелинейных зависимостей, которые линейная модель уловить не может.

### 8.2. Lasso (L1-регуляризация)

Модель обучена на тех же данных (масштабированных).

- **Train:** R² ≈ 0.539  
- **Test:** R² ≈ 0.569  
- **Коэффициенты:** ни один признак не был занулён.

**Вывод:** при стандартном `alpha` L1-регуляризация не дала улучшений и не обнулила признаки — все шесть признаков важны для модели, что соответствует их высокой корреляции с целевой.

### 8.3. Lasso с подбором гиперпараметров (GridSearchCV)

Произведён перебор по `alpha` и `max_iter`. Лучший набор дал:

- **Train:** R² ≈ 0.538  
- **Test:** R² ≈ 0.563  
- **Коэффициенты:** занулены 2 признака (оба получены из torque).

**Вывод:** подбор гиперпараметров усилил регуляризацию, но качество на тесте почти не улучшилось (стало даже чуть хуже). Lasso действительно начала «отбрасывать» слабые признаки.

### 8.4. ElasticNet (L1 + L2)

Подбор по сетке (`alpha`, `l1_ratio`, `max_iter`).

- **Train:** R² ≈ 0.539  
- **Test:** R² ≈ 0.566  
- **Лучшие параметры:** `alpha≈0.0127`, `l1_ratio≈0.1`

**Вывод:** небольшое улучшение по сравнению с Lasso, так как ElasticNet компенсирует недостатки чистого L1 и более стабилен при мультиколлинеарности. Однако прирост метрик минимален: линейность по-прежнему ограничивает качество.

### 8.5. IHT (Iterative Hard Thresholding, аналог L0-регуляризации)

Реализован алгоритм, который на каждой итерации оставляет только `k` крупнейших коэффициентов.

Проведено тестирование k = 1…6:

| k признаков | Test R²   | Test MSE    |
| ----------- | --------- | ----------- |
| 1           | 0.262     | 4.24e11     |
| 2           | 0.300     | 4.02e11     |
| 3           | 0.329     | 3.86e11     |
| 4           | 0.353     | 3.72e11     |
| 5           | 0.352     | 3.72e11     |
| **6**       | **0.353** | **3.72e11** |

**Вывод:**  
- Модель с малым количеством признаков сильно недообучена — высокие ошибки и низкий R².  
- Лучшим оказался k=6, то есть **алгоритм не смог отбрасывать признаки без сильного падения качества**.  
- Это согласуется с предыдущими результатами: все шесть вещественных признаков содержат существенную информацию.

### Общий итог по моделям

- Регуляризации (L1, L2, ElasticNet, IHT) почти не улучшают качество — признаки важны и мультиколлинеарны.
- Наилучшие результаты достигаются либо классической линейной моделью, либо ElasticNet (но разница минимальна).

## 9. Обработка категориальных признаков и модель с ними

### 9.1.  Формирование нового категориального признака 

  \- Из столбца `name` выделен бренд как первое слово в названии автомобиля (`brand`).

  \- В трейне обнаружено 30 уникальных брендов, что слишком много для прямого включения в модель.

  \- Для каждого бренда посчитана средняя `selling_price`.

  \- На вектор средних цен по брендам обучён `KMeans` с `n_clusters = 5` (кластеризация по ценовому сегменту).

  \- Получено отображение `brand → brand_cluster`, затем каждому объекту в трейн/тест присвоен номер кластера бренда.

  \- Столбец `name` заменён на числовой признак — номер ценового кластера бренда, вспомогательные столбцы `brand` и `brand_cluster` удалены.


### 9.2.  Подготовка данных и кодирование категориальных признаков


  \- Числовые признаки (`mileage`, `engine`, `max_power`, `torque`, `max_torque_rpm`, `km_driven`) заменены на их стандартизованные версии из предыдущего шага (масштабирование `StandardScaler`).

  \- Для категориальных столбцов `["fuel", "seller_type", "transmission", "owner", "name", "seats"]` применён `OneHotEncoder(handle_unknown="ignore")` через `ColumnTransformer`.

  \- В результате получены матрицы признаков `X_train_enc`, `X_test_enc` с one-hot-кодированием категориальных и добавленными вещественными признаками (через `remainder="passthrough"`).

### 9.3.  **Модель Ridge-регрессии с подбором гиперпараметра**

  \- На расширенном наборе признаков (вещественные + one-hot категориальные) обучена Ridge-регрессия.

  \- Гиперпараметр `alpha` подбирался по сетке `logspace(-4, 4, 20)` с помощью `GridSearchCV` (`cv=10`, метрика — `R²`).

  \- Лучшая модель показала следующие результаты:

   \- **Train:** `R² ≈ 0.741`, `MSE ≈ 7.43⋅10¹⁰`

   \- **Test:** `R² ≈ 0.756`, `MSE ≈ 1.40⋅10¹¹`

   \- Лучший `alpha ≈ 4.28`.

  **Вывод:**  

  Добавление категориальных признаков (включая кластер бренда) и использование Ridge-регрессии дало заметный прирост качества по сравнению с моделями только на вещественных признаках (R² вырос примерно с ~0.56 до ~0.75). Разрыв между трейном и тестом невелик, признаки работают стабильнее, а регуляризация Ridge помогает контролировать переобучение при большом количестве one-hot-признаков.
## 10. Feature Engineering и бизнес-метрики

### 10.1. Исследование выбросов и преобразование числовых признаков

Перед построением новых признаков были исследованы боксплоты всех числовых переменных. По результатам анализа:

1. **Логарифмирование признаков**  
   Для признаков с явно скошенными распределениями созданы log-версии:  
   - `max_power_log`, `engine_log`, `torque_log`  
   
2. **Производный признак эффективности двигателя**  
   Добавлен признак мощности на литр двигателя:  
   \[
   \text{power\_per\_liter} = \frac{\text{max\_power}}{\text{engine}}
   \]  

3. **Обработка выбросов**  
   - `torque` обрезан по перцентилям 1%–99%.  
   - Подозрительно малые значения `mileage < 2` заменены медианой.

4. **Новые признаки по пробегу**  
   - Логарифм пробега `km_driven_log`;  
   - Бинарный индикатор высоких пробегов `is_high_mileage`.

5. **Возраст автомобиля**  
   Вместо года введены признаки:
   - `age = 2024 - year`;  
   - `age_sq` — квадрат возраста (позволяет уловить нелинейный рост износа).

### 10.2. Назначение типа автомобиля

Создан новый категориальный признак `car_class`, определяющий тип кузова/класса авто:  
`luxury`, `suv`, `mpv`, `sedan`, `hatchback`, `pickup`, `other`.  
Он был сформирован по словарю ключевых слов в названии модели.

### 10.3. Кодирование категориальных признаков и объединение признаков

- Все числовые признаки были стандартизованы (`StandardScaler`).
- Для категориальных столбцов `["fuel", "seller_type", "transmission", "owner", "name", "seats", "car_class"]`
  применён `OneHotEncoder(handle_unknown="ignore")`.
- Итоговый набор признаков — разреженная матрица `X_train_bonus`, содержащая:
  - новые числовые признаки,
  - преобразованные старые числовые,
  - one-hot кодированные категориальные признаки.

### 10.4. Обучение Ridge-регрессии на расширенном наборе признаков

Для итоговой модели проведён подбор гиперпараметра `alpha` на сетке `logspace(-4, 4, 20)`.

**Метрики лучшей модели:**

- **Train:** R² ≈ 0.772, MSE ≈ 6.55⋅10¹⁰  
- **Test:** R² ≈ 0.783, MSE ≈ 1.25⋅10¹¹  
- Лучший `alpha ≈ 4.28`

**Вывод:**  
Feature Engineering дал прирост по сравнению с моделью «Ridge + категориальные признаки без FE» (R² вырос с ~0.756 до ~0.783).  
Прирост умеренный, что ожидаемо.


### 10.5. Бизнес-метрики

Помимо технических метрик (R², MSE) были рассчитаны две бизнес-ориентированные метрики.

#### **1. Бизнес-метрика: доля предсказаний с ошибкой ≤10%**

\[
\text{score} = \frac{1}{n}\sum \mathbb{1}\left(\frac{|y - \hat y|}{y} \le 0.10\right)
\]

| Модель | Метрика (≤10%) |
|--------|----------------|
| Линейные / Lasso / ElasticNet | ~0.18 |
| Ridge | **0.285** |
| IHT | 0.157 |
| Ridge с FE | 0.264 |

**Вывод:** лучшая модель по бизнес-логике №1 — обычная Ridge-регрессия.  
Она даёт максимальную долю предсказаний, попадающих в ±10% от истинной цены.


#### **2. Бизнес-метрика кастомная: штраф за недопрогноз + относительная ошибка**

Метрика учитывает три идеи:
- показатель должен быть **в процентах** (понятно бизнесу);
- **недопрогноз штрафуется сильнее**, потому что приводит к реальным потерям;
- чем сильнее недопрогноз, тем быстрее растёт штраф (квадрат ошибки).

\[
\text{score} = 
1 - \mathbb{E}\left[
\begin{cases}
\text{rel\_err} + \beta\cdot\text{rel\_err}^2, & \hat y < y\\
\text{rel\_err}, & \hat y \ge y\\
\end{cases}
\right]
\]

Результаты:

| Модель | Кастомная метрика |
|--------|-------------------|
| Линейные модели | 0.0 |
| Ridge | 0.043 |
| IHT | 0.291 |
| **Ridge с FE** | **0.464** |

**Вывод:**  
По кастомной бизнес-метрике лучшая модель — **Ridge с Feature Engineering**.  
Она значительно снижает величину недопрогноза и даёт лучший результат среди всех моделей.


### Итог по разделу Feature Engineering

- FE дал модели дополнительную информацию о структуре рынка: возраст авто, логарифмы, пробег, класс авто.
- Улучшения технических метрик есть, но они умеренные.
- **Бизнес-метрики показывают, что добавленные признаки критически важны**,  
  т.к. значительно влияют именно на практическую точность предсказаний.
- Итоговая лучшая модель для бизнеса — **Ridge с Feature Engineering**.

## 11. Оценка разработанного сервиса (Streamlit-приложение)

Разработан веб-сервис на Streamlit, который реализует полный цикл работы с моделью:
- загрузка обученного Ridge-классификатора и обучающего датасета;
- EDA по трейну или загруженному пользователем датасету;
- предсказание по загруженному CSV;
- предсказание цены для одного автомобиля через форму;
- просмотр весов модели.

### Удобство использования

- Интерфейс разделён на  вкладки: **«EDA»**, **«Предсказание по CSV»**, **«Предсказание для одной записи»**, **«Веса модели»**.
- Формы для ввода признаков в режиме «одна запись» максимально приближены к исходному датасету.
- Для предсказаний по CSV реализована возможность:
  - загрузить файл;
  - увидеть первые строки предсказаний;
  - скачать результат с добавленной колонкой `prediction`.
- Основные тяжёлые операции (загрузка модели, загрузка трейна) кешируются (`st.cache_resource`).

В приложении загружается csv файл из ноутбука, по умолчанию именно по нему проходят перенесенные из ноутбука преобразования (и EDA визуализации). Можно загрузить и свой файл для просмотра EDA, но только в том же формате. 
Так сделано из-за того что функции для приведения датасета к виду понимаемому моделью все равно необходимо перенести для создания предсказаний по пользовательским данным. В таком случае нет смысла сохранять данные обработки датасета в `pickle`, можно просто обработать исходный датасет (он маленький) и при этом дать пользователю больший функционал (для работы со своим файлом).

### Визуализации

**Удачно реализовано:**
- Базовый обзор данных:
  - вывод размеров датасета;
  - `head()`;
  - `describe()` отдельно для числовых и категориальных переменных.
- Набор  графиков:
  - выбор колонок и отображение боксплотов (позволяет быстро оценить выбросы);
  - тепловая карта корреляции (по Пирсону);
  - возможность построить `pairplot`;
  - LOWESS-графики зависимости цены от года и пробега;
  - phik-корреляции (по кнопке, с предупреждением о возможной длительности).
- Отдельная страница с весами модели:
  - отображение таблицы с топ-N признаков по модулю коэффициента;
  - горизонтальная диаграмма с коэффициентами.

**Менее удачно / ограниченно:**
- Веса модели показываются с абстрактными именами `f_0`, `f_1`, … (без привязки к исходным фичам), поэтому интерпретация важности признаков затруднена.
- Pairplot и phik могут работать долго и не очень дружелюбно выглядят на больших наборах признаков (визуальная перегруженность, но от нее не уйти в такого вида графиках + наш датасет адекватный).

### Планируемые улучшения

На текущем этапе сервис закрывает базовые сценарии (EDA, предсказания по одной записи и по CSV, просмотр весов модели), поэтому конкретных доработок в следующей итерации **не планируется**.  